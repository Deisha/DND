# -*- coding: utf-8 -*-
"""CODE_startupmate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SOBxQcZYlEa-3aEWqp9sV8Un2fahzPVt
"""

!pip install pdfplumber
!pip install pytesseract
!pip install requests
!pip install Pillow


!apt-get install -y tesseract-ocr
import os
import pdfplumber
import pytesseract
import requests


os.environ["GROQ_API_KEY"] = "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"
GROQ_CLOUD_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_CLOUD_API_KEY:
    raise ValueError("Groq Cloud API key not found. Please set the GROQ_API_KEY environment variable.")

def extract_text_from_pdf(pdf_path):
    """Extracts text from the PDF, handles both text-based and image-based pages."""
    full_text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                full_text += text + "\n"
            else:
                print(f"Page {page_num + 1} contains images, using OCR...")
                image = page.to_image().original
                ocr_text = pytesseract.image_to_string(image)
                full_text += ocr_text + "\n"
    return full_text

def get_api_response(conversation_history, max_tokens=4000):
    """Queries the external API for a response based on the conversation history."""
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {GROQ_CLOUD_API_KEY}",
    }
    data = {
        "model": "llama3-8b-8192",
        "messages": conversation_history,
        "max_tokens": max_tokens  # Adjust token limit for larger inputs
    }

    response = requests.post(url, headers=headers, json=data)
    if response.ok:
        response_data = response.json()
        return response_data["choices"][0]["message"]["content"]
    else:
        return f"Error: {response.status_code} - {response.text}"

def chunk_text_with_overlap(text, max_length=5000, overlap=500):
    """Splits the text into larger chunks with some overlap between them to maintain context."""
    paragraphs = text.split("\n")
    chunks = []
    current_chunk = ""

    for para in paragraphs:
        if len(current_chunk) + len(para) > max_length:
            chunks.append(current_chunk)
            current_chunk = current_chunk[-overlap:] + para
        else:
            current_chunk += "\n" + para

    if current_chunk:
        chunks.append(current_chunk)

    return chunks


pdf_files = [
    "/content/jumpstart.pdf",
    "/content/harvard.pdf",
    "/content/start1.pdf"
]


all_extracted_text = ""
for pdf_path in pdf_files:
    extracted_text = extract_text_from_pdf(pdf_path)
    all_extracted_text += extracted_text + "\n"


    chunks = chunk_text_with_overlap(all_extracted_text, max_length=5000, overlap=500)

    conversation_history = [{"role": "system", "content": "You are an AI assistant helping a solo founder named Alex. Alex is navigating their startup journey and seeks advice on various topics like idea validation, fundraising, and growth."}]

    print("Welcome to StartupMate - Your AI Assistant for Founders!")
    print("You can now ask questions related to your startup journey or request more insights!")
    print("Type 'exit' to end the conversation.\n")

    while True:
        question = input("You: ")
        if question.lower() == 'exit':
            break


        conversation_history.append({"role": "user", "content": question})


        full_answer = get_api_response(conversation_history, max_tokens=4000)

        conversation_history.append({"role": "assistant", "content": full_answer})

        print("StartupMate:")
        print(full_answer)